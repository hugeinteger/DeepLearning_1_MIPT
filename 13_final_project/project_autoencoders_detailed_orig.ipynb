{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQ7i1HkmYY68"
   },
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7rYVufslYY7D"
   },
   "source": [
    "В этом ноутбуке мы будем тренировать автоэнкодеры кодировать лица людей. Для этого возьмем следующий датасет: \"Labeled Faces in the Wild\" (LFW) (http://vis-www.cs.umass.edu/lfw/). Код для скачивания и загрузки датасета написан за вас в файле get_dataset.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wru2LNFuL2Iq"
   },
   "source": [
    "# Vanilla Autoencoder (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr3STtdpYY7G"
   },
   "source": [
    "## Prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTNi9JLRYY7I"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3KhlblLYY7P"
   },
   "outputs": [],
   "source": [
    "# The following line fetches you two datasets: images, usable for autoencoder training and attributes.\n",
    "# Those attributes will be required for the final part of the assignment (applying smiles), so please keep them in mind\n",
    "from get_dataset import fetch_dataset\n",
    "data, attrs = fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oW_Jsi42YY7T"
   },
   "outputs": [],
   "source": [
    "IMAGE_H = data.shape[1]\n",
    "IMAGE_W = data.shape[2]\n",
    "# у нас цветные изображения\n",
    "N_CHANNELS = 3\n",
    "\n",
    "TRAIN_SIZE = 10000\n",
    "VAL_SIZE = data.shape[0] - TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MSzXXGoYY7X"
   },
   "source": [
    "\n",
    "Разбейте выборку картинок на train и val и приведите значения элементов в интервал [0, 1] типа float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFc8lTm_YY7Y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = <тут Ваш код>\n",
    "X_val = <тут Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MES0waD1YY7c"
   },
   "source": [
    "Напишем вспомогательную функцию, которая будет выводить n_row $\\cdot$ n_col первых картинок в массиве images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3z2ZvgS0YY7d"
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, h, w, n_row=3, n_col=6):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        try:\n",
    "            plt.imshow(images[i].reshape((h, w, 3)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n",
    "            plt.xticks(())\n",
    "            plt.yticks(())\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fk2Vi_vJYY7e"
   },
   "outputs": [],
   "source": [
    "plot_gallery(X_train, image_h, image_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-yV79BQYY7g"
   },
   "source": [
    "Осталось привести картинки к тензорам из PyTorch, чтобы можно было потом скармливать их автоэнкодеру: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H__1M-rKYY7h"
   },
   "outputs": [],
   "source": [
    "<тут Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9CC-DUhYY7i"
   },
   "source": [
    "## Autoencoder\n",
    "\n",
    "Why to use all this complicated formulaes and regularizations, what is the need for variational inference? To analyze the difference, let's first train just an autoencoder on the data:\n",
    "<img src=\"https://i.imgur.com/nVJAtMT.png\" alt=\"Autoencoder\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csrNCYh-YY7j"
   },
   "outputs": [],
   "source": [
    "inp_size=X_train.shape[1]\n",
    "hid_size=250\n",
    "dimZ = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fjr-N8AWee-k"
   },
   "source": [
    "Реализуем autoencoder. Архитектуру (conv, fully-connected, ReLu, etc) можете выбирать сами. Экспериментируйте!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SjHNX-rYY7k"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        <определите архитектуры encoder и decoder>\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        <реализуйте forward проход автоэнкодера\n",
    "        в качестве ваозвращаемых переменных -- латентное представление картинки (latent_code) \n",
    "        и полученная реконструкция изображения (reconstruction)>\n",
    "        \n",
    "        return reconstruction, latent_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73lg3bI2YY7m"
   },
   "outputs": [],
   "source": [
    "criterion = <MSE LOSS>\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "optimizer = <Ваш любимый оптимизатор>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bdxg_3WJYY7o"
   },
   "source": [
    "Осталось написать код обучения автоэнкодера. При этом было бы неплохо в процессе иногда смотреть, как автоэнкодер реконструирует изображения на данном этапе обучения. Наример, после каждой эпохи (прогона train выборки через автоэекодер) можно смотреть, какие реконструкции получились для каких-то изображений val выборки.\n",
    "\n",
    "Подсказка: если x_val -- каринка, а reconstruction -- ее реконструкция автоэнкодером, то красиво вывести эту каритинку и ее реконструкцию можно с помощью функции plot_gallery вот так:\n",
    "\n",
    "*plot_gallery([x_val, reconstruction], image_h, image_w, n_row=1, n_col=2)*\n",
    "\n",
    "А, ну еще было бы неплохо выводить графики train и val лоссов в процессе тренировки =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H3DOojrYY7o",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<тут Ваш код тренировки автоэнкодера>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAztAMA4YY7q"
   },
   "source": [
    "Давайте посмотрим, как наш тренированный автоэекодер кодирует и восстанавливает картинки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1J__yvxYY7r"
   },
   "outputs": [],
   "source": [
    "< тут Ваш код: выведите первые Х картинок и их реконструкций из val выборки на экран>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OPh9O6UYY7s"
   },
   "source": [
    "Not bad, right? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFi96giuYY7t"
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOtUaPNYYY7t"
   },
   "source": [
    "Давайте теперь будем не просто брать картинку, прогонять ее через автоэекодер и получать реконструкцию, а попробуем создать что-то НОВОЕ\n",
    "\n",
    "Давайте возьмем и подсунем декодеру какие-нибудь сгенерированные нами векторы (например, из нормального распределения) и посмотрим на результат реконструкции декодера:\n",
    "\n",
    "#### If that doesn't work\n",
    "Если вместо лиц у вас выводится непонятно что, попробуйте посмотреть, как выглядят латентные векторы картинок из датасета. Так как в обучении нейронных сетей есть определенная доля рандома, векторы латентного слоя могут быть распределены НЕ как np.random.randn(25, <latent_space_dim>). А чтобы у нас получались лица при запихивании вектора декодеру, вектор должен быть распределен так же, как лаьентные векторы реальных фоток. Так что ридется рандом подогнать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IZykARRYY7u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# сгенерируем 25 рандомных векторов размера latent_space\n",
    "z = np.random.randn(25, <latent_space_dim>)\n",
    "output = <скормите z декодеру>\n",
    "plot_gallery(output.data.cpu().numpy(), IMAGE_H, IMAGE_W, n_row=5, n_col=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "Ey8dD9s0YY7w"
   },
   "source": [
    "## Congrats!\n",
    "\n",
    "Time to make fun!\n",
    "\n",
    "Давайте научимся пририсовывать людям улыбки =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1v-8WwuYY7w"
   },
   "source": [
    "<img src=\"https://i.imgur.com/tOE9rDK.png\" alt=\"linear\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGE0M2GDYY7x"
   },
   "source": [
    "План такой:\n",
    "\n",
    "1) Нужно выделить \"вектор улыбки\": для этого нужно из выборки изображений найти несколько (~15 сойдет) людей с улыбками и столько же без.\n",
    "\n",
    "Найти людей с улыбками вам поможет файл с описанием датасета, скачанный вместе с датасетом. В нем указаны имена картинок и присутствубщие атрибуты (улыбки, очки...)\n",
    "\n",
    "2) Вычислить латентный вектор для всех улыбающихся людей (прогнать их через encoder) и то же для всех грустненьких\n",
    "\n",
    "3) Вычислить, собственно, вектор улыбки -- посчитать разность между средним латентным вектором улыбающихся людей и средним латентным вектором грустных людей\n",
    "\n",
    "3) А теперь приделаем улыбку грустному человеку: добавим полученный в пункте 3 вектор к латентному вектору грустного чувака и прогоним полученный вектор через decoder. Получим того же человека, но уже не грустненького!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1oBX9EeYY7x"
   },
   "outputs": [],
   "source": [
    "<а вот тут все это надо запрогать, да>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXI6jprOYY7z"
   },
   "source": [
    "Вуаля! Вы восхитительны!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2UAf0bpYY70"
   },
   "source": [
    "Теперь вы можете пририсовывать людям не только улыбки, но и много чего другого -- закрывать/открывать глаза, пририсовывать очки... в общем, все, на что хватит фантазии)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIYuKFwijN2U"
   },
   "source": [
    "# Conditional Autoencoder (3 балла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4ABYDnLMe1e"
   },
   "source": [
    "Мы уже научились обучать обычный AE на датасете картинок и получать новые картинки, используя генерацию шума и декодер. \n",
    "Давайте теперь допустим, что мы обучили AE на датасете MNIST и теперь хотим генерировать новые картинки с числами с помощью декодера (как выше мы генерили рандомные лица). \n",
    "И вот мне понадобилось сгенерировать цифру 8. И я подставляю разные варианты шума, и все никак не генерится восьмерка -- у меня получаются то пятерки, то тройки, то четверки. Гадость(\n",
    "\n",
    "  Хотелось бы добавить к нашему AE функцию \"выдай мне пожалуйста рандомное число из вот этого вот класса\", где классов десять (цифры от 0 до 9 образуют десять классов).\n",
    "  Типа я такая говорю \"выдай мне случайную восьмерку\" и оно генерит случайную восьмерку!\n",
    "\n",
    "Conditional AE -- так называется вид автоэнкодера, который предоставляет такую возможность. Ну, название \"conditional\" уже говорит само за себя.\n",
    "\n",
    "И в этой части проекта мы научимся такие обучать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSp3u2vmuMiQ"
   },
   "source": [
    "## Архитектура\n",
    "\n",
    "На картинке ниже представлена архитектура простого Conditional AE.\n",
    "\n",
    "По сути, единственное отличие от обычного -- это то, что мы вместе с картинкой в первом слое энкодера и декодера передаем еще информацию о классе картинки. \n",
    "\n",
    "То есть, в первый (входной) слой энкодера есть конкатенация картинки и информации о классе (например, вектора из девяти нулей и одной единицы). Первый слой декодера есть конкатенация латентного вектора и информации о классе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5Xu3YuUrjGX"
   },
   "source": [
    "\n",
    "![alt text](https://i.ibb.co/2tsWknB/Screen-Shot-2020-01-15-at-9-02-15-PM.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1gA28KVvT5Z"
   },
   "source": [
    "Таким образом, при генерации новой рандомной картинки мы должны будем передать декодеру сконкатенированные латентный вектор и класс картинки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJa6QD87vqm8"
   },
   "source": [
    "### P.S.\n",
    "Можно ередавать класс картинки не только в первый слой, но и в каждый слой сети. То есть на каждом слое конкатенировать выход из предыдущего слоя и информацию о классе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ICnlbsAt6Vt"
   },
   "source": [
    "### Датасет\n",
    "\n",
    "Как вы уже догадались, здесь мы будем использовать датасет MNIST (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Если он вам очень не нравится, можете загуглить любой другой, в котором будет четкое разделение картинок по классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvn50Lf_v2j9"
   },
   "outputs": [],
   "source": [
    "<тут надо обработать датасет, построить и обучить Conditional AE (код обычного AE прекрасно берется за основу)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxVAEW0ywF6W"
   },
   "source": [
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyV0vcFiwTDO"
   },
   "outputs": [],
   "source": [
    "<тут нужно научиться сэмплировать из декодера цифры определенного класса>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnxBdgmE0lMG"
   },
   "source": [
    "Splendid! Вы великолепны!\n",
    "\n",
    "Теперь давайте сделаем следующее: посмотрим на то, как выглядит латентное пространство векторов, соответствующих нашим картинкам. \n",
    "Для этого вам нужно:\n",
    "1.  прогнать картинки из датасета через encoder, получить латентные векторы\n",
    "2. Прогнать векторы через TSNE, получить их двумерную проекцию\n",
    "3. Изобразить полученные после TSNE двумерные векторы на плоскости с помощью plt.scatter, покрасив точки в цвета в зависимости от класса картинки, которой она соответствует. (как красить точки, см. в документации к plt.scatter). \n",
    "4. Подумать, что вы видите и записать свои мысли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aylvuymY2dwl"
   },
   "outputs": [],
   "source": [
    "<тут код получения латентных векторов, прогона через TSNE и рисования scatter plot>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_Y5iVuu2kJ2"
   },
   "source": [
    "<тут ваши мысли по поводу того, что вы видите на рисунке>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQnEGmknYY71"
   },
   "source": [
    "# BONUS 1. (2 балла) \n",
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWQNRjJq2uTz"
   },
   "source": [
    "Если вы (надеюсь) осознали, в каком месте у conditional AE выше могли бы быть проблемы, то -- тадам!!\n",
    "\n",
    "Представляю вам проапгрейдженную версию автоэнкодеров -- вариационные автоэнкодеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nb5AHMcxYY73"
   },
   "source": [
    "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoNVT5tYYY74"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        <определите архитектуры encoder и decoder\n",
    "        помните, у encoder должны быть два \"хвоста\", \n",
    "        т.е. encoder должен кодировать картинку в 2 переменные -- mu и logsigma>\n",
    "\n",
    "    def encode(self, x):\n",
    "        <реализуйте forward проход энкодера\n",
    "        в качестве ваозвращаемых переменных -- mu и logsigma>\n",
    "        \n",
    "        return mu, logsigma\n",
    "    \n",
    "    def gaussian_sampler(self, mu, logsigma):\n",
    "        \"\"\"\n",
    "        Функция сэмплирует латентные векторы из нормального распределения с параметрами mu и sigma\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            std = logsigma.exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        <реализуйте forward проход декодера\n",
    "        в качестве ваозвращаемой переменной -- reconstruction>\n",
    "        \n",
    "        return reconstruction\n",
    "\n",
    "    def forward(self, x):\n",
    "        <используя encode и decode, реализуйте forward проход автоэнкодера\n",
    "        в качестве ваозвращаемых переменных -- mu, logsigma и reconstruction>\n",
    "        return mu, logsigma, mu_z, reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAB77d-PYY76"
   },
   "source": [
    "Определим лосс и его компоненты для VAE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ac5ey7uIYY77"
   },
   "outputs": [],
   "source": [
    "def KL_divergence(mu, logsigma):\n",
    "    \"\"\"\n",
    "    часть функции потерь, которая отвечает за \"близость\" латентных представлений разных людей\n",
    "    \"\"\"\n",
    "    return -(1/2) * (1 + 2*logsigma - mu**2 - torch.exp(logsigma)**2).sum(dim=-1)\n",
    "\n",
    "def log_likelihood(x, reconstruction):\n",
    "    \"\"\"\n",
    "    часть функции потерь, которая отвечает за качество реконструкции (как mse в обычном autoencoder)\n",
    "    \"\"\"\n",
    "    loss = nn.BCELoss()\n",
    "    return loss(reconstruction, x)\n",
    "\n",
    "def loss_vae(x, mu, logsigma, reconstruction):\n",
    "    return -(-KL_divergence(mu, logsigma) + log_likelihood(x, reconstruction)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPJQu70eYY79"
   },
   "source": [
    "И обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtCjfqXdYY79"
   },
   "outputs": [],
   "source": [
    "criterion = <MSE LOSS>\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "optimizer = <Ваш любимый оптимизатор>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY1khca6YY7_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<обучите модель, как и autoencoder>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkxW_8fkYY8B",
    "scrolled": true
   },
   "source": [
    "Давайте посмотрим, как наш тренированный VAE кодирует и восстанавливает картинки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Jd3BWM_YY8C"
   },
   "outputs": [],
   "source": [
    "< тут Ваш код: выведите первые Х картинок и их реконструкций из val выборки на экран>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0jI-FKEYY8E"
   },
   "source": [
    "And finally sample from VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Po-KV8E8YY8F"
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQXYIXjoYY8F"
   },
   "source": [
    "Давайте попробуем проделать для VAE то же, что и с обычным автоэнкодером -- подсунуть decoder'у из VAE случайные векторы из нормального распределения и посмотреть, какие лица получатся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOhhH-osYY8G"
   },
   "outputs": [],
   "source": [
    "# вспомните про замечание из этого же ункта обычного AE про распределение латентных переменных\n",
    "z = np.array([np.random.normal(0, 1, 100) for i in range(10)])\n",
    "output = <скормите z декодеру>\n",
    "plot_gallery(output.data.cpu().numpy(), IMAGE_H, IMAGE_W, n_row=2, n_col=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESPBHrL3YY8H"
   },
   "source": [
    "## Congrats v2.0!\n",
    "\n",
    "Как вы уже догадались, здесь тоже можно попробовать пририсовывать разные атрибуты людям. Можно, например, так же пририсовать улыбки и сравнить с тем, как это получалось у обычного автоэнкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tq-hgOk-YY8I"
   },
   "outputs": [],
   "source": [
    "<как вы уже догадались, тут Ваш код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x7jA3PRvhAv5"
   },
   "source": [
    "# BONUS 2. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woSjtsK63Lan"
   },
   "source": [
    "А теперь пришло время сделать \n",
    "## Conditional Variational AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZf-Dr9-hFAt"
   },
   "outputs": [],
   "source": [
    "<тут обучение Conditional Variational AE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rt2S77cm3O1v"
   },
   "source": [
    "... и так же посмотреть на латентное пространство векторов VAE, как мы делали это с обычным variational AE, понять, чем же оно отличается и сделать выводы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LSCYK7sH3KEc"
   },
   "outputs": [],
   "source": [
    "<тут код>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ET8IELWu3Z2c"
   },
   "source": [
    "<тут выводы>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KN3D_k5W_WZz"
   },
   "source": [
    "# BONUS 3. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12a1jkpkCsIU"
   },
   "source": [
    "У автоэнкодеров, кроме сжатия и генерации изображений, есть другие практические применения. Про одно из них это бонксное задание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8EN-8jlCtmd"
   },
   "source": [
    "Автоэнкодеры могут быть использованы для избавления от шума на фотографиях (denoising). Для этого их нужно обучить специальным образом: input картинка будет зашумленной, а выдавать автоэнкодер должен будет картинку без шума. \n",
    "То есть, loss-функция AE останется той же (MSE между реальной картинкой и выданной), а на вход автоэнкодеру будет подаваться зашумленная картинка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysI0BCuRDbvm"
   },
   "source": [
    "Для того, чтобы поставить эксперимент, нужно взять ваш любимый датасет (датасет лиц или MSE с прошлых заданий или любой другой) и сделать копию этого датасета с шумом. \n",
    "\n",
    "В питоне шум можно добавить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5e746iVDgSm"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "X_noisy = X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fSPkXMtDpd5"
   },
   "outputs": [],
   "source": [
    "<тут ваш код обучения автоэнкодера на зашумленных картинках. Не забудтье разбить на train/test!>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B03NQ_sKDvg2"
   },
   "outputs": [],
   "source": [
    "<тут проверка, как AE убирает щум с тестовых картинок. Надеюсь, все получилось =)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qA5xi_AvRjrU"
   },
   "source": [
    "# Bonus 4. (2+ балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHEYlsVHRzIE"
   },
   "source": [
    "Пишем телеграм-бота!\n",
    "\n",
    "Можно написать телеграм-бота, которому на вход вы подаете, например, картинку без улыбки, а он вам возвращает с улыбкой.\n",
    "\n",
    "Или еще много вариантов, чего может уметь делать бот. Придумайте сами)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-KAfd5pLCBS"
   },
   "source": [
    "# Эпилог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SDI06AONLYKG"
   },
   "source": [
    "здесь мы рассмотрели не все применения автоэнкодеров. Еще есть, например:\n",
    "\n",
    "-- поиск аномалий\n",
    "-- дополнение отсутствующих частей картины\n",
    "-- работа с sequential данными (например, временными рядами)\n",
    "-- гибриды ГАН+АЕ, которые активно изучаются в последнее время\n",
    "-- использование латентных переменных АЕ в качестве фичей\n",
    "...\n",
    "\n",
    "Они не были частью этого проекта, потому что для их реализации пришлось бы больше возиться с датасетами. \n",
    "\n",
    "Но! Если вы хотите, вы, конечно, всегда можете реализовать еще что-то и получить за это еще допбаллы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBCiWOicLwLI"
   },
   "source": [
    "Надеюсь, вам понравилось!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LQ7i1HkmYY68",
    "Wru2LNFuL2Iq",
    "yIYuKFwijN2U",
    "QQnEGmknYY71",
    "x7jA3PRvhAv5",
    "KN3D_k5W_WZz",
    "qA5xi_AvRjrU",
    "M-KAfd5pLCBS"
   ],
   "name": "project_autoencoders_detailed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
